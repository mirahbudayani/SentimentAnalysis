{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036003c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=kMJDsh0TCik\n",
    "#https://github.com/Syukrondzeko/Python-Tutorial/blob/master/Sentiment_TF_IDF.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import string, re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7dbe80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/mirah/OneDrive/TA/DATAWITHSENTIMENT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28e2f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Adiiiinnnnnn Harusnya adik2 juga mengapresias...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapa yang bangun tidur masih terharu sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Still astonished and thrilled about the Indone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nyambeksyariah harus lawan pake UU TPKS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saksikan Perjuangan DPR RI bersama Rakyat untu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>Ketua DPR Puan Maharani mendapat penghargaan t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>Tindak Pidana Kekerasan Seksual (RUU TPKS) men...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Saat pengesahan Puan menangis Karena Undang-Un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>Salah satu poin penolakan PKS adalah agar RUU ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>Keberhasilan Puan tak diragukan lagi ,dengan k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Sentiment\n",
       "0     @Adiiiinnnnnn Harusnya adik2 juga mengapresias...          0\n",
       "1     Siapa yang bangun tidur masih terharu sekarang...          1\n",
       "2     Still astonished and thrilled about the Indone...          1\n",
       "3              @nyambeksyariah harus lawan pake UU TPKS          1\n",
       "4     Saksikan Perjuangan DPR RI bersama Rakyat untu...          1\n",
       "...                                                 ...        ...\n",
       "5481  Ketua DPR Puan Maharani mendapat penghargaan t...          1\n",
       "5482  Tindak Pidana Kekerasan Seksual (RUU TPKS) men...          1\n",
       "5483  Saat pengesahan Puan menangis Karena Undang-Un...          1\n",
       "5484  Salah satu poin penolakan PKS adalah agar RUU ...          0\n",
       "5485  Keberhasilan Puan tak diragukan lagi ,dengan k...          1\n",
       "\n",
       "[5486 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560a7cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5091\n",
       "0     395\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8146f874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adiiiinnnnnn Harusnya adik juga mengapresiasi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapa yang bangun tidur masih terharu sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Still astonished and thrilled about the Indone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyambeksyariah harus lawan pake UU TPKS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saksikan Perjuangan DPR RI bersama Rakyat untu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0   Adiiiinnnnnn Harusnya adik juga mengapresiasi...          0\n",
       "1  Siapa yang bangun tidur masih terharu sekarang...          1\n",
       "2  Still astonished and thrilled about the Indone...          1\n",
       "3            nyambeksyariah harus lawan pake UU TPKS          1\n",
       "4  Saksikan Perjuangan DPR RI bersama Rakyat untu...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleansing data\n",
    "def cleansing(data):\n",
    "    #hapus https\n",
    "    data = re.sub(r'http\\S+', '', data)\n",
    "    data = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", data)\n",
    "    data = re.sub(r'\\d+', '', data)\n",
    "    \n",
    "    # hapus punctuation\n",
    "    remove = string.punctuation\n",
    "    translator = str.maketrans(remove, ' '*len(remove))\n",
    "    data = data.translate(translator)\n",
    "    \n",
    "    # remove ASCII dan unicode\n",
    "    data = data.encode('ascii', 'ignore').decode('utf-8')\n",
    "    data = re.sub(r'[^\\x00-\\x7f]',r'', data)\n",
    "    \n",
    "    # remove newline\n",
    "    data = data.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n",
    "    \n",
    "    #hapus whitespace\n",
    "    pattern = re.compile(r'\\s+') \n",
    "    data = re.sub(pattern, ' ', data)\n",
    "    # There are some instances where there is no space after '?' & ')', \n",
    "    # So I am replacing these with one space so that It will not consider two words as one token.\n",
    "    data = data.replace('?', ' ? ').replace(')', ') ')\n",
    "    \n",
    "    # # this is a docstring\n",
    "    \"\"\"\n",
    "    The function will remove accented characters from the \n",
    "    text contained within the Dataset.\n",
    "       \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" with removed accented characters.\n",
    "        \n",
    "    Example:\n",
    "    Input : Málaga, àéêöhello\n",
    "    Output : Malaga, aeeohello    \n",
    "        \n",
    "    \"\"\"\n",
    "    # Remove accented characters from text using unidecode.\n",
    "    # Unidecode() - It takes unicode data & tries to represent it to ASCII characters. \n",
    "    data = unidecode.unidecode(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# jalankan cleansing data\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(cleansing(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec2abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/mirah/OneDrive/TA/aftercleansing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4f5c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adiiiinnnnnn Harusnya adik juga mengapresiasi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapa yang bangun tidur masih terharu sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Still astonished and thrilled about the Indone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyambeksyariah harus lawan pake UU TPKS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saksikan Perjuangan DPR RI bersama Rakyat untu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KompasTV UU TPKS sudah berlaku hukum seberat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aktivis Perempuan Kelompok Cipayung Maluku Sor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mau download uu tpks dmn yah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sridiana va berlianidris dr fadh programnya b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Speedtrap dari sini ada benang merahnya baran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dukung banget another next pit stop after UU T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yang ini harus segera naik UU TPKS Kelahiranny...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>infotwitwor Lucifer ga tau apa UU TPKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Flying bird bread selling Adinda fitri Politi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pakar Hukum Unair Optimis UU TPKS Jadi Langkah...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aktivis Perempuan Kelompok Cipayung Maluku Sor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DavidWijaya MardaniAliSera Orang PKS kan oran...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UNSfess Nder itu bisa dilaporin ke pihak berw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Waspada Liberalisasi Seks Generasi UU TPKS Per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cah UU TPKS tentang kekerasan seksual itu kalo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet  Sentiment\n",
       "0    Adiiiinnnnnn Harusnya adik juga mengapresiasi...          0\n",
       "1   Siapa yang bangun tidur masih terharu sekarang...          1\n",
       "2   Still astonished and thrilled about the Indone...          1\n",
       "3             nyambeksyariah harus lawan pake UU TPKS          1\n",
       "4   Saksikan Perjuangan DPR RI bersama Rakyat untu...          1\n",
       "5    KompasTV UU TPKS sudah berlaku hukum seberat ...          1\n",
       "6   Aktivis Perempuan Kelompok Cipayung Maluku Sor...          1\n",
       "7                        Mau download uu tpks dmn yah          1\n",
       "8    Sridiana va berlianidris dr fadh programnya b...          1\n",
       "9    Speedtrap dari sini ada benang merahnya baran...          1\n",
       "10  dukung banget another next pit stop after UU T...          1\n",
       "11  Yang ini harus segera naik UU TPKS Kelahiranny...          1\n",
       "12             infotwitwor Lucifer ga tau apa UU TPKS          0\n",
       "13   Flying bird bread selling Adinda fitri Politi...          1\n",
       "14  Pakar Hukum Unair Optimis UU TPKS Jadi Langkah...          1\n",
       "15  Aktivis Perempuan Kelompok Cipayung Maluku Sor...          1\n",
       "16   DavidWijaya MardaniAliSera Orang PKS kan oran...          0\n",
       "17   UNSfess Nder itu bisa dilaporin ke pihak berw...          1\n",
       "18  Waspada Liberalisasi Seks Generasi UU TPKS Per...          0\n",
       "19  Cah UU TPKS tentang kekerasan seksual itu kalo...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7edaf5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adin Harusnya adik juga mengapresiasi disahka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapa yang bangun tidur masih terharu sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stil astonished and thriled about the Indonesi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyambeksyariah harus lawan pake U TPKS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saksikan Perjuangan DPR RI bersama Rakyat untu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0   Adin Harusnya adik juga mengapresiasi disahka...          0\n",
       "1  Siapa yang bangun tidur masih terharu sekarang...          1\n",
       "2  Stil astonished and thriled about the Indonesi...          1\n",
       "3             nyambeksyariah harus lawan pake U TPKS          1\n",
       "4  Saksikan Perjuangan DPR RI bersama Rakyat untu...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''https://swatimeena989.medium.com/beginners-guide-for-preprocessing-text-data-f3156bec85ca\n",
    "def cleansing(data):\n",
    "    data=re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", 'string_inp')\n",
    "    return data\n",
    "# jalankan cleansing data\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(cleansing(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()'''\n",
    "# remove consecutive duplicates from string\n",
    "def remove_consec_duplicates(s):\n",
    "    new_s = \"\"\n",
    "    prev = \"\"\n",
    "    for c in s:\n",
    "        if len(new_s) == 0:\n",
    "            new_s += c\n",
    "            prev = c\n",
    "        if c == prev:\n",
    "            continue\n",
    "        else:\n",
    "            new_s += c\n",
    "            prev = c\n",
    "    return new_s\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(remove_consec_duplicates(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148ab382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/mirah/OneDrive/TA/aftercleansing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bfb3368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adin harusnya adik juga mengapresiasi disahka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siapa yang bangun tidur masih terharu sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stil astonished and thriled about the indonesi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyambeksyariah harus lawan pake u tpks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saksikan perjuangan dpr ri bersama rakyat untu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0   adin harusnya adik juga mengapresiasi disahka...          0\n",
       "1  siapa yang bangun tidur masih terharu sekarang...          1\n",
       "2  stil astonished and thriled about the indonesi...          1\n",
       "3             nyambeksyariah harus lawan pake u tpks          1\n",
       "4  saksikan perjuangan dpr ri bersama rakyat untu...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleansing(data):\n",
    "    # lower text\n",
    "    data = data.lower()\n",
    "    return data\n",
    "\n",
    "# jalankan cleansing data\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(cleansing(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95ca66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/mirah/OneDrive/TA/casefolding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4d5ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adin harusnya adik mengapresiasi disahkanya u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siapa bangun tidur terharu sekarang nyebut u t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stil astonished and thriled about the indonesi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyambeksyariah lawan pake u tpks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saksikan perjuangan dpr ri bersama rakyat u tp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0   adin harusnya adik mengapresiasi disahkanya u...          0\n",
       "1  siapa bangun tidur terharu sekarang nyebut u t...          1\n",
       "2  stil astonished and thriled about the indonesi...          1\n",
       "3                   nyambeksyariah lawan pake u tpks          1\n",
       "4  saksikan perjuangan dpr ri bersama rakyat u tp...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    " \n",
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    " \n",
    "# Contoh\n",
    "kalimat = 'Dengan Menggunakan Python dan Library Sastrawi saya dapat melakukan proses Stopword Removal'\n",
    "stop = stopword.remove(kalimat)\n",
    "#print(stop)\n",
    "\n",
    "# lakukan pada data kita\n",
    "\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(stopword.remove(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7dd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/mirah/OneDrive/TA/stopword.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268c7c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun']\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da2e9627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adin harusnya adik mengapresiasi disahkanya u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siapa bangun tidur terharu sekarang nyebut u t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stil astonished and thriled about the indonesi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyambeksyariah lawan pake u tpks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saksikan perjuangan dpr ri bersama rakyat u tp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kompastv u tpks berlaku hukum seberat beratnya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aktivis perempuan kelompok cipayung maluku sor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mau download u tpks dmn yah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sridiana va berlianidris dr fadh programnya b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spedtrap sini benang merahnya barangkali pkse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dukung banget another next pit stop after u tp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>segera naik u tpks kelahiranya disambut gembir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>infotwitwor lucifer ga tau apa u tpks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>flying bird bread seling adinda fitri politik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pakar hukum unair optimis u tpks jadi langkah ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aktivis perempuan kelompok cipayung maluku sor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>davidwijaya mardanialisera orang pks kan oran...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>unsfes nder dilaporin pihak berwajib kan u tp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>waspada liberalisasi seks generasi u tpks perl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cah u tpks kekerasan seksual kalo lapor dmn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>euforia u tpks membahana media sosial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yeay bulan benar banyak hadiah perempuan indon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ru tpks resmi disahkan menjadi undang undang t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>live akhbar forum tokoh partai surabaya meres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>finalis puteri indonesia perwakilan dki jakart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ranikancana u tpks mdhan bs dipake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>puan meminta seluruh masyarakat ikut mengawal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>puan mengajak seluruh masyarakat berdoa bersam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>puan berpesan u tpks segera diterjemahkan menj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>puan menyampaikan terima kasih pemerintah atas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet  Sentiment\n",
       "0    adin harusnya adik mengapresiasi disahkanya u...          0\n",
       "1   siapa bangun tidur terharu sekarang nyebut u t...          1\n",
       "2   stil astonished and thriled about the indonesi...          1\n",
       "3                    nyambeksyariah lawan pake u tpks          1\n",
       "4   saksikan perjuangan dpr ri bersama rakyat u tp...          1\n",
       "5      kompastv u tpks berlaku hukum seberat beratnya          1\n",
       "6   aktivis perempuan kelompok cipayung maluku sor...          1\n",
       "7                         mau download u tpks dmn yah          1\n",
       "8    sridiana va berlianidris dr fadh programnya b...          1\n",
       "9    spedtrap sini benang merahnya barangkali pkse...          1\n",
       "10  dukung banget another next pit stop after u tp...          1\n",
       "11  segera naik u tpks kelahiranya disambut gembir...          1\n",
       "12              infotwitwor lucifer ga tau apa u tpks          0\n",
       "13   flying bird bread seling adinda fitri politik...          1\n",
       "14  pakar hukum unair optimis u tpks jadi langkah ...          1\n",
       "15  aktivis perempuan kelompok cipayung maluku sor...          1\n",
       "16   davidwijaya mardanialisera orang pks kan oran...          0\n",
       "17   unsfes nder dilaporin pihak berwajib kan u tp...          1\n",
       "18  waspada liberalisasi seks generasi u tpks perl...          0\n",
       "19       cah u tpks kekerasan seksual kalo lapor dmn           1\n",
       "20             euforia u tpks membahana media sosial           1\n",
       "21  yeay bulan benar banyak hadiah perempuan indon...          1\n",
       "22  ru tpks resmi disahkan menjadi undang undang t...          1\n",
       "23   live akhbar forum tokoh partai surabaya meres...          1\n",
       "24  finalis puteri indonesia perwakilan dki jakart...          1\n",
       "25                 ranikancana u tpks mdhan bs dipake          1\n",
       "26  puan meminta seluruh masyarakat ikut mengawal ...          1\n",
       "27  puan mengajak seluruh masyarakat berdoa bersam...          1\n",
       "28  puan berpesan u tpks segera diterjemahkan menj...          1\n",
       "29  puan menyampaikan terima kasih pemerintah atas...          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "\n",
    "s = 'Aku pernah mendengar Aisya bercerita bahwa sebenarnya ia tidak terlalu senang dengan kabar perjodohan yang diatur oleh orang tuanya.'\n",
    "\n",
    "# Ambil Stopword bawaan\n",
    "stop_factory = StopWordRemoverFactory().get_stop_words()\n",
    "more_stopword = [\"apa\", \"tau\",\"mjd\", \"sbg\", \"dgn\", \"dg\", \"loh\", \"lho\", \"the\", \"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\"]\n",
    "\n",
    "# Merge stopword\n",
    "data = stop_factory + more_stopword\n",
    "\n",
    "dictionary = ArrayDictionary(data)\n",
    "strr = StopWordRemover(dictionary)\n",
    "\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(stopword.remove(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d42800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# contoh\n",
    "kalimat = 'Liverpool adalah klub hebat tidak seperti si itu WkwkWK'\n",
    "katadasar = stemmer.stem(kalimat)\n",
    " \n",
    "#print(katadasar)\n",
    "\n",
    "# implementasi pada data kita\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(stemmer.stem(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b326245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/mirah/OneDrive/TA/stemming.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da8e5d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[adin, harus, adik, apresiasi, disahkanya, utp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[siapa, bangun, tidur, haru, sekarang, nyebut,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[stil, astonished, thriled, indonesian, parlia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nyambeksyariah, lawan, pake, tpks]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[saksi, juang, dpr, sama, rakyat, tpks, sama, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  [adin, harus, adik, apresiasi, disahkanya, utp...          0\n",
       "1  [siapa, bangun, tidur, haru, sekarang, nyebut,...          1\n",
       "2  [stil, astonished, thriled, indonesian, parlia...          1\n",
       "3                [nyambeksyariah, lawan, pake, tpks]          1\n",
       "4  [saksi, juang, dpr, sama, rakyat, tpks, sama, ...          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "def cleansing(data):\n",
    "    tokenizer=word_tokenize()\n",
    "    return data\n",
    "review = []\n",
    "for index, row in df.iterrows():\n",
    "    review.append(word_tokenize(row[\"Tweet\"]))\n",
    "    \n",
    "df[\"Tweet\"] = review\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "046a824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tweet\"] = df[\"Tweet\"].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bffc2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['adin', 'harus', 'adik', 'apresiasi', 'disahk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['siapa', 'bangun', 'tidur', 'haru', 'sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['stil', 'astonished', 'thriled', 'indonesian'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['nyambeksyariah', 'lawan', 'pake', 'tpks']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['saksi', 'juang', 'dpr', 'sama', 'rakyat', 't...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>['ketua', 'dpr', 'puan', 'maharani', 'dapat', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>['tindak', 'pidana', 'keras', 'seksual', 'tpks...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>['sat', 'kesah', 'puan', 'menang', 'undang', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>['salah', 'satu', 'poin', 'tolak', 'pks', 'tpk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>['hasil', 'puan', 'tak', 'ragu', 'mampu', 'nya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Sentiment\n",
       "0     ['adin', 'harus', 'adik', 'apresiasi', 'disahk...          0\n",
       "1     ['siapa', 'bangun', 'tidur', 'haru', 'sekarang...          1\n",
       "2     ['stil', 'astonished', 'thriled', 'indonesian'...          1\n",
       "3           ['nyambeksyariah', 'lawan', 'pake', 'tpks']          1\n",
       "4     ['saksi', 'juang', 'dpr', 'sama', 'rakyat', 't...          1\n",
       "...                                                 ...        ...\n",
       "5481  ['ketua', 'dpr', 'puan', 'maharani', 'dapat', ...          1\n",
       "5482  ['tindak', 'pidana', 'keras', 'seksual', 'tpks...          1\n",
       "5483  ['sat', 'kesah', 'puan', 'menang', 'undang', '...          1\n",
       "5484  ['salah', 'satu', 'poin', 'tolak', 'pks', 'tpk...          0\n",
       "5485  ['hasil', 'puan', 'tak', 'ragu', 'mampu', 'nya...          1\n",
       "\n",
       "[5486 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf4db8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/mirah/OneDrive/TA/tokenizing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714ac41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/mirah/OneDrive/TA/tokenizing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffcae85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['adin', 'harus', 'adik', 'apresiasi', 'disahk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['siapa', 'bangun', 'tidur', 'haru', 'sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['stil', 'astonished', 'thriled', 'indonesian'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['nyambeksyariah', 'lawan', 'pake', 'tpks']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['saksi', 'juang', 'dpr', 'sama', 'rakyat', 't...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>['ketua', 'dpr', 'puan', 'maharani', 'dapat', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>['tindak', 'pidana', 'keras', 'seksual', 'tpks...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>['sat', 'kesah', 'puan', 'menang', 'undang', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>['salah', 'satu', 'poin', 'tolak', 'pks', 'tpk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>['hasil', 'puan', 'tak', 'ragu', 'mampu', 'nya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Sentiment\n",
       "0     ['adin', 'harus', 'adik', 'apresiasi', 'disahk...          0\n",
       "1     ['siapa', 'bangun', 'tidur', 'haru', 'sekarang...          1\n",
       "2     ['stil', 'astonished', 'thriled', 'indonesian'...          1\n",
       "3           ['nyambeksyariah', 'lawan', 'pake', 'tpks']          1\n",
       "4     ['saksi', 'juang', 'dpr', 'sama', 'rakyat', 't...          1\n",
       "...                                                 ...        ...\n",
       "5481  ['ketua', 'dpr', 'puan', 'maharani', 'dapat', ...          1\n",
       "5482  ['tindak', 'pidana', 'keras', 'seksual', 'tpks...          1\n",
       "5483  ['sat', 'kesah', 'puan', 'menang', 'undang', '...          1\n",
       "5484  ['salah', 'satu', 'poin', 'tolak', 'pks', 'tpk...          0\n",
       "5485  ['hasil', 'puan', 'tak', 'ragu', 'mampu', 'nya...          1\n",
       "\n",
       "[5486 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0556171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweet'], df['Sentiment'], \n",
    "                                                    test_size=0.2, stratify=df['Sentiment'], random_state=None)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb33aa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4051)\t0.4260730014833264\n",
      "  (0, 5458)\t0.18606330967071671\n",
      "  (0, 4600)\t0.7000606332315316\n",
      "  (0, 5326)\t0.5419938671247446\n",
      "  (1, 3108)\t0.30225102783426266\n",
      "  (1, 2108)\t0.39469535424064\n",
      "  (1, 5023)\t0.39469535424064\n",
      "  (1, 1542)\t0.5056819243388152\n",
      "  (1, 2791)\t0.41227357277445104\n",
      "  (1, 2786)\t0.40537746443193606\n",
      "  (1, 5458)\t0.08402901150412194\n",
      "  (2, 3495)\t0.30390911364615963\n",
      "  (2, 4583)\t0.4319686283391864\n",
      "  (2, 5086)\t0.27849314675643083\n",
      "  (2, 1565)\t0.29336053430649267\n",
      "  (2, 2137)\t0.09542346071656595\n",
      "  (2, 4596)\t0.07970870622049464\n",
      "  (2, 5519)\t0.16744484491648334\n",
      "  (2, 1304)\t0.11850927421920138\n",
      "  (2, 3892)\t0.17354342631943814\n",
      "  (2, 4393)\t0.17960544161779848\n",
      "  (2, 303)\t0.17682927919751565\n",
      "  (2, 1907)\t0.19286081180621215\n",
      "  (2, 4753)\t0.09476573026693488\n",
      "  (2, 2491)\t0.0938404455627029\n",
      "  :\t:\n",
      "  (4386, 1826)\t0.2514016111638957\n",
      "  (4386, 4737)\t0.3010980952422346\n",
      "  (4386, 2502)\t0.19698177857440896\n",
      "  (4386, 1835)\t0.2702656473984925\n",
      "  (4386, 5677)\t0.13507329028278722\n",
      "  (4386, 3841)\t0.14737764335653877\n",
      "  (4386, 4055)\t0.14749179824609387\n",
      "  (4386, 4312)\t0.127659576556243\n",
      "  (4386, 2137)\t0.15923303392692098\n",
      "  (4386, 4051)\t0.16272224344421132\n",
      "  (4387, 4141)\t0.33493561493968893\n",
      "  (4387, 5700)\t0.358772622819975\n",
      "  (4387, 2610)\t0.358772622819975\n",
      "  (4387, 1112)\t0.33129713115261317\n",
      "  (4387, 5746)\t0.2835816307565966\n",
      "  (4387, 2729)\t0.358772622819975\n",
      "  (4387, 3872)\t0.22833366125681756\n",
      "  (4387, 5845)\t0.23939714151124852\n",
      "  (4387, 2502)\t0.15806014896909343\n",
      "  (4387, 2528)\t0.22113586122972112\n",
      "  (4387, 2033)\t0.16315305027959023\n",
      "  (4387, 2356)\t0.2270583411611114\n",
      "  (4387, 2240)\t0.1722875307373096\n",
      "  (4387, 4051)\t0.13056995538123622\n",
      "  (4387, 5458)\t0.057019050625626955\n"
     ]
    }
   ],
   "source": [
    "# implementasi pada dokumen kita\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce76ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3460885720028406\n",
      "  (0, 3)\t0.3460885720028406\n",
      "  (0, 21)\t0.20440548581747317\n",
      "  (0, 13)\t0.3460885720028406\n",
      "  (0, 17)\t0.3460885720028406\n",
      "  (0, 7)\t0.3460885720028406\n",
      "  (0, 20)\t0.3460885720028406\n",
      "  (0, 1)\t0.3460885720028406\n",
      "  (0, 19)\t0.3460885720028406\n",
      "  (1, 6)\t0.3968745408286403\n",
      "  (1, 12)\t0.3968745408286403\n",
      "  (1, 8)\t0.3968745408286403\n",
      "  (1, 18)\t0.3968745408286403\n",
      "  (1, 10)\t0.3968745408286403\n",
      "  (1, 4)\t0.3968745408286403\n",
      "  (1, 21)\t0.23440049712476196\n",
      "  (2, 11)\t0.3460885720028406\n",
      "  (2, 2)\t0.3460885720028406\n",
      "  (2, 5)\t0.3460885720028406\n",
      "  (2, 16)\t0.3460885720028406\n",
      "  (2, 22)\t0.3460885720028406\n",
      "  (2, 9)\t0.3460885720028406\n",
      "  (2, 15)\t0.3460885720028406\n",
      "  (2, 14)\t0.3460885720028406\n",
      "  (2, 21)\t0.20440548581747317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus=[\"siapa bangun tidur haru sekarang nyebut tpks bukan aku\", \"cah tpks keras seksual kalo lapor dmn\", \"tpks resmi sah kenal yuk sama dana bantu korban\"]\n",
    "vectorizer=TfidfVectorizer()\n",
    "hasil=vectorizer.fit_transform(corpus)\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf28e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aku', 'bangun', 'bantu', 'bukan', 'cah', 'dana', 'dmn', 'haru',\n",
       "       'kalo', 'kenal', 'keras', 'korban', 'lapor', 'nyebut', 'resmi',\n",
       "       'sah', 'sama', 'sekarang', 'seksual', 'siapa', 'tidur', 'tpks',\n",
       "       'yuk'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ca5a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.34608857, 0.34608857, 0.        , 0.34608857, 0.        ,\n",
       "         0.        , 0.        , 0.34608857, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.34608857, 0.        ,\n",
       "         0.        , 0.        , 0.34608857, 0.        , 0.34608857,\n",
       "         0.34608857, 0.20440549, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.39687454,\n",
       "         0.        , 0.39687454, 0.        , 0.39687454, 0.        ,\n",
       "         0.39687454, 0.        , 0.39687454, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.39687454, 0.        ,\n",
       "         0.        , 0.2344005 , 0.        ],\n",
       "        [0.        , 0.        , 0.34608857, 0.        , 0.        ,\n",
       "         0.34608857, 0.        , 0.        , 0.        , 0.34608857,\n",
       "         0.        , 0.34608857, 0.        , 0.        , 0.34608857,\n",
       "         0.34608857, 0.34608857, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.20440549, 0.34608857]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc8428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aku</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bangun</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bantu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bukan</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cah</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dana</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmn</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haru</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kalo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kenal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korban</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lapor</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyebut</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resmi</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sah</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sama</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sekarang</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seksual</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siapa</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tidur</th>\n",
       "      <td>0.346089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpks</th>\n",
       "      <td>0.204405</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.204405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuk</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                D1        D2        D3\n",
       "aku       0.346089  0.000000  0.000000\n",
       "bangun    0.346089  0.000000  0.000000\n",
       "bantu     0.000000  0.000000  0.346089\n",
       "bukan     0.346089  0.000000  0.000000\n",
       "cah       0.000000  0.396875  0.000000\n",
       "dana      0.000000  0.000000  0.346089\n",
       "dmn       0.000000  0.396875  0.000000\n",
       "haru      0.346089  0.000000  0.000000\n",
       "kalo      0.000000  0.396875  0.000000\n",
       "kenal     0.000000  0.000000  0.346089\n",
       "keras     0.000000  0.396875  0.000000\n",
       "korban    0.000000  0.000000  0.346089\n",
       "lapor     0.000000  0.396875  0.000000\n",
       "nyebut    0.346089  0.000000  0.000000\n",
       "resmi     0.000000  0.000000  0.346089\n",
       "sah       0.000000  0.000000  0.346089\n",
       "sama      0.000000  0.000000  0.346089\n",
       "sekarang  0.346089  0.000000  0.000000\n",
       "seksual   0.000000  0.396875  0.000000\n",
       "siapa     0.346089  0.000000  0.000000\n",
       "tidur     0.346089  0.000000  0.000000\n",
       "tpks      0.204405  0.234400  0.204405\n",
       "yuk       0.000000  0.000000  0.346089"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bobot=pd.DataFrame(hasil.todense().T, index=vectorizer.get_feature_names_out(), columns=[f'D{i+1}' for i in range (len(corpus))])\n",
    "bobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb4fd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['adin', 'harus', 'adik', 'apresiasi', 'disahk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['siapa', 'bangun', 'tidur', 'haru', 'sekarang...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['stil', 'astonished', 'thriled', 'indonesian'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['nyambeksyariah', 'lawan', 'pake', 'tpks']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['saksi', 'juang', 'dpr', 'sama', 'rakyat', 't...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['kompastv', 'tpks', 'laku', 'hukum', 'berat',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['aktivis', 'perempuan', 'kelompok', 'cipayung...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['mau', 'download', 'tpks', 'dmn', 'yah']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['sridiana', 'berlianidris', 'fadh', 'program'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['spedtrap', 'sini', 'benang', 'merah', 'baran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['dukung', 'banget', 'pit', 'tpks', 'legalizat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['segera', 'naik', 'tpks', 'kelahiranya', 'sam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['infotwitwor', 'lucifer', 'u', 'tpks']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['flying', 'bird', 'bread', 'seling', 'adinda'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['pakar', 'hukum', 'unair', 'optimis', 'tpks',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['aktivis', 'perempuan', 'kelompok', 'cipayung...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['davidwijaya', 'mardanialisera', 'orang', 'pk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['unsfes', 'nder', 'dilaporin', 'pihak', 'waji...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['waspada', 'liberalisasi', 'seks', 'generasi'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['cah', 'tpks', 'keras', 'seksual', 'kalo', 'l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['euforia', 'tpks', 'bahana', 'media', 'sosial']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['yeay', 'bulan', 'benar', 'banyak', 'hadiah',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['tpks', 'resmi', 'sah', 'jadi', 'undang', 'un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['live', 'akhbar', 'forum', 'tokoh', 'partai',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['final', 'puter', 'indonesia', 'wakil', 'dki'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['ranikancana', 'tpks', 'mdhan', 'dipake']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['puan', 'minta', 'seluruh', 'masyarakat', 'ik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['puan', 'ajak', 'seluruh', 'masyarakat', 'doa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['puan', 'pesan', 'tpks', 'segera', 'terjemah'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['puan', 'sampai', 'terima', 'kasih', 'perinta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet  Sentiment\n",
       "0   ['adin', 'harus', 'adik', 'apresiasi', 'disahk...          0\n",
       "1   ['siapa', 'bangun', 'tidur', 'haru', 'sekarang...          1\n",
       "2   ['stil', 'astonished', 'thriled', 'indonesian'...          1\n",
       "3         ['nyambeksyariah', 'lawan', 'pake', 'tpks']          1\n",
       "4   ['saksi', 'juang', 'dpr', 'sama', 'rakyat', 't...          1\n",
       "5   ['kompastv', 'tpks', 'laku', 'hukum', 'berat',...          1\n",
       "6   ['aktivis', 'perempuan', 'kelompok', 'cipayung...          1\n",
       "7           ['mau', 'download', 'tpks', 'dmn', 'yah']          1\n",
       "8   ['sridiana', 'berlianidris', 'fadh', 'program'...          1\n",
       "9   ['spedtrap', 'sini', 'benang', 'merah', 'baran...          1\n",
       "10  ['dukung', 'banget', 'pit', 'tpks', 'legalizat...          1\n",
       "11  ['segera', 'naik', 'tpks', 'kelahiranya', 'sam...          1\n",
       "12            ['infotwitwor', 'lucifer', 'u', 'tpks']          0\n",
       "13  ['flying', 'bird', 'bread', 'seling', 'adinda'...          1\n",
       "14  ['pakar', 'hukum', 'unair', 'optimis', 'tpks',...          1\n",
       "15  ['aktivis', 'perempuan', 'kelompok', 'cipayung...          1\n",
       "16  ['davidwijaya', 'mardanialisera', 'orang', 'pk...          0\n",
       "17  ['unsfes', 'nder', 'dilaporin', 'pihak', 'waji...          1\n",
       "18  ['waspada', 'liberalisasi', 'seks', 'generasi'...          0\n",
       "19  ['cah', 'tpks', 'keras', 'seksual', 'kalo', 'l...          1\n",
       "20   ['euforia', 'tpks', 'bahana', 'media', 'sosial']          1\n",
       "21  ['yeay', 'bulan', 'benar', 'banyak', 'hadiah',...          1\n",
       "22  ['tpks', 'resmi', 'sah', 'jadi', 'undang', 'un...          1\n",
       "23  ['live', 'akhbar', 'forum', 'tokoh', 'partai',...          1\n",
       "24  ['final', 'puter', 'indonesia', 'wakil', 'dki'...          1\n",
       "25         ['ranikancana', 'tpks', 'mdhan', 'dipake']          1\n",
       "26  ['puan', 'minta', 'seluruh', 'masyarakat', 'ik...          1\n",
       "27  ['puan', 'ajak', 'seluruh', 'masyarakat', 'doa...          1\n",
       "28  ['puan', 'pesan', 'tpks', 'segera', 'terjemah'...          1\n",
       "29  ['puan', 'sampai', 'terima', 'kasih', 'perinta...          1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c288369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93394077, 0.92938497, 0.93166287, 0.92482916, 0.92938497,\n",
       "       0.92482916, 0.92938497, 0.93166287, 0.93150685, 0.93150685])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "svmlinear=cross_val_score(clf, X_train, y_train, cv=10)\n",
    "svmlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f80f5c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# lakukan prediksi pada data test\\nclf.fit(X_train,y_train)\\npredict = clf.predict(X_test)\\n\\n# import library evaluation\\nfrom sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score\\n\\n# f1_score\\nprint(f1_score(y_test, predict, pos_label=1))\\n\\n# accuracy score\\nprint(\"accuracy score hasil prediksi adalah: \")\\nprint(accuracy_score(y_test, predict))\\n\\n# precision score\\nprint(\"precision score hasil prediksi adalah: \")\\nprint(precision_score(y_test, predict, pos_label=1))\\n\\n# recall score\\nprint(\"recall score hasil prediksi adalah: \")\\nprint(recall_score(y_test, predict, pos_label=1))\\n# f1 score\\nprint(\"f1 score hasil prediksi adalah: \")\\nprint(f1_score(y_test, predict, pos_label=1))\\n# confusion matrix\\nprint(confusion_matrix(y_test, predict))'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "'''# lakukan prediksi pada data test\n",
    "clf.fit(X_train,y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# import library evaluation\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# f1_score\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# accuracy score\n",
    "print(\"accuracy score hasil prediksi adalah: \")\n",
    "print(accuracy_score(y_test, predict))\n",
    "\n",
    "# precision score\n",
    "print(\"precision score hasil prediksi adalah: \")\n",
    "print(precision_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# recall score\n",
    "print(\"recall score hasil prediksi adalah: \")\n",
    "print(recall_score(y_test, predict, pos_label=1))\n",
    "# f1 score\n",
    "print(\"f1 score hasil prediksi adalah: \")\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, predict))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4612e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626830420406235\n",
      "accuracy score hasil prediksi adalah: \n",
      "0.9280510018214936\n",
      "precision score hasil prediksi adalah: \n",
      "0.9280510018214936\n",
      "recall score hasil prediksi adalah: \n",
      "1.0\n",
      "f1 score hasil prediksi adalah: \n",
      "0.9626830420406235\n",
      "[[   0   79]\n",
      " [   0 1019]]\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "clf = svm.SVC(kernel=\"poly\")\n",
    "\n",
    "#cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "# lakukan prediksi pada data test\n",
    "clf.fit(X_train,y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# import library evaluation\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# f1_score\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# accuracy score\n",
    "print(\"accuracy score hasil prediksi adalah: \")\n",
    "print(accuracy_score(y_test, predict))\n",
    "\n",
    "# precision score\n",
    "print(\"precision score hasil prediksi adalah: \")\n",
    "print(precision_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# recall score\n",
    "print(\"recall score hasil prediksi adalah: \")\n",
    "print(recall_score(y_test, predict, pos_label=1))\n",
    "# f1 score\n",
    "print(\"f1 score hasil prediksi adalah: \")\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99134471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626830420406235\n",
      "accuracy score hasil prediksi adalah: \n",
      "0.9280510018214936\n",
      "precision score hasil prediksi adalah: \n",
      "0.9280510018214936\n",
      "recall score hasil prediksi adalah: \n",
      "1.0\n",
      "f1 score hasil prediksi adalah: \n",
      "0.9626830420406235\n",
      "[[   0   79]\n",
      " [   0 1019]]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "#cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "# lakukan prediksi pada data test\n",
    "clf.fit(X_train,y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# import library evaluation\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# f1_score\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# accuracy score\n",
    "print(\"accuracy score hasil prediksi adalah: \")\n",
    "print(accuracy_score(y_test, predict))\n",
    "\n",
    "# precision score\n",
    "print(\"precision score hasil prediksi adalah: \")\n",
    "print(precision_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# recall score\n",
    "print(\"recall score hasil prediksi adalah: \")\n",
    "print(recall_score(y_test, predict, pos_label=1))\n",
    "# f1 score\n",
    "print(\"f1 score hasil prediksi adalah: \")\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "837a1379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9644043663977219\n",
      "accuracy score hasil prediksi adalah: \n",
      "0.9316939890710383\n",
      "precision score hasil prediksi adalah: \n",
      "0.9338235294117647\n",
      "recall score hasil prediksi adalah: \n",
      "0.9970559371933267\n",
      "f1 score hasil prediksi adalah: \n",
      "0.9644043663977219\n",
      "[[   7   72]\n",
      " [   3 1016]]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel=\"sigmoid\")\n",
    "\n",
    "#cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "# lakukan prediksi pada data test\n",
    "clf.fit(X_train,y_train)\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# import library evaluation\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# f1_score\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# accuracy score\n",
    "print(\"accuracy score hasil prediksi adalah: \")\n",
    "print(accuracy_score(y_test, predict))\n",
    "\n",
    "# precision score\n",
    "print(\"precision score hasil prediksi adalah: \")\n",
    "print(precision_score(y_test, predict, pos_label=1))\n",
    "\n",
    "# recall score\n",
    "print(\"recall score hasil prediksi adalah: \")\n",
    "print(recall_score(y_test, predict, pos_label=1))\n",
    "# f1 score\n",
    "print(\"f1 score hasil prediksi adalah: \")\n",
    "print(f1_score(y_test, predict, pos_label=1))\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "954628e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of Naive Bayes algo is : 0.9325539568345323\n",
      "[[   0   75]\n",
      " [   0 1037]]\n",
      "Accuracy Score :  0.9325539568345323\n",
      "Precision Score :  0.9325539568345323\n",
      "Recall Score : 1.0\n",
      "F1-Score : 0.9651000465332712\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES\n",
    "#https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "nb= MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "score = nb.score(X_test, y_test)\n",
    "print(\"score of Naive Bayes algo is :\" , score)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score : \",accuracy_score(y_test,y_pred,))\n",
    "print(\"Precision Score : \",precision_score(y_test,y_pred,pos_label=1))\n",
    "print(\"Recall Score :\" , recall_score(y_test, y_pred, pos_label=1) )\n",
    "print(\"F1-Score :\" , f1_score(y_test, y_pred, pos_label=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2108dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
